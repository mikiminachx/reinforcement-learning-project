{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1234acd1-29c9-49fc-852d-ae5338ce634c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pip\n",
    "! pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31e8e05f-c735-488a-b459-fa397b494b0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import multiprocessing\n",
    "from tensorflow.keras.models import load_model, clone_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.utils import custom_object_scope\n",
    "from functools import partial\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# Read the Excel sheet\n",
    "df = pd.read_excel('EmotionsIGTData.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ab7d84d-3ebc-45fc-b6e0-1ca9d7355983",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the CustomIGTEnvironment class\n",
    "class CustomIGTEnvironment:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.num_trials = len(data)\n",
    "        self.current_trial = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_trial = 0\n",
    "        initial_state = np.array([0, 0, 0, 0])  # Initial state, assuming all decks are unchosen\n",
    "        return initial_state\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.current_trial >= self.num_trials:\n",
    "            raise ValueError(\"Episode is already done. Call reset() to start a new episode.\")\n",
    "\n",
    "        current_trial_data = self.data.iloc[self.current_trial]\n",
    "        self.current_trial += 1\n",
    "        state_space = np.array([current_trial_data['IGT_NET_Raw'], current_trial_data['IGT_NET_1Raw'],\n",
    "                                current_trial_data['IGT_NET_2Raw'], current_trial_data['IGT_NET_3Raw']])\n",
    "\n",
    "        reward = calculate_reward(state_space, action)  # Implement calculate_reward function\n",
    "        done = (self.current_trial >= self.num_trials)\n",
    "\n",
    "        return state_space, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "160c2652-509d-42b7-8cae-5b06c635dc98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomAdamOptimizer(tf.keras.optimizers.Optimizer):\n",
    "    def __init__(self, learning_rate=0.001, **kwargs):\n",
    "        name = kwargs.pop('name', 'CustomAdamOptimizer')\n",
    "        super(CustomAdamOptimizer, self).__init__(name=name, **kwargs)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(CustomAdamOptimizer, self).get_config()\n",
    "        config.update({\n",
    "            'learning_rate': self.learning_rate,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def _create_slots(self, var_list):\n",
    "        for var in var_list:\n",
    "            self.add_slot(var, 'm')\n",
    "            self.add_slot(var, 'v')\n",
    "\n",
    "    def _resource_apply_dense(self, grad, var, **kwargs):\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = tf.cast(self.learning_rate, var_dtype)\n",
    "        beta1_t = tf.constant(0.9, dtype=var_dtype)\n",
    "        beta2_t = tf.constant(0.999, dtype=var_dtype)\n",
    "        epsilon_t = tf.constant(1e-7, dtype=var_dtype)\n",
    "\n",
    "        m = self.get_slot(var, 'm')\n",
    "        v = self.get_slot(var, 'v')\n",
    "\n",
    "        m_t = m.assign(beta1_t * m + (1.0 - beta1_t) * grad)\n",
    "        v_t = v.assign(beta2_t * v + (1.0 - beta2_t) * grad * grad)\n",
    "\n",
    "        var_update = var.assign_sub(lr_t * m_t / (tf.sqrt(v_t) + epsilon_t))\n",
    "\n",
    "        return var_update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "140b2070-4ce6-4fce-a4ca-9eec8c9abd04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-72dfe475b997>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    165\u001b[0m     results = pool.starmap(\n\u001b[1;32m    166\u001b[0m         \u001b[0mfine_tune_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscount_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_optimizer_instance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscount_factor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhyperparameters_to_search\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-72dfe475b997>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    165\u001b[0m     results = pool.starmap(\n\u001b[1;32m    166\u001b[0m         \u001b[0mfine_tune_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscount_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_optimizer_instance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscount_factor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhyperparameters_to_search\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# Define a custom_objects dictionary to register the custom optimizer\n",
    "custom_objects = {'CustomAdamOptimizer': CustomAdamOptimizer}\n",
    "\n",
    "# Create an instance of the custom optimizer\n",
    "custom_optimizer_instance = CustomAdamOptimizer(learning_rate=0.001)\n",
    "\n",
    "# Use the custom optimizer when compiling the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=4, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(4, activation='linear'))\n",
    "model.compile(optimizer=custom_optimizer_instance, loss='mean_squared_error')\n",
    "\n",
    "env = CustomIGTEnvironment(df)\n",
    "\n",
    "# Register the custom optimizer class with its name\n",
    "with custom_object_scope(custom_objects):\n",
    "\n",
    "  # Define the function to load models with custom optimizer\n",
    "  def load_model_with_custom_optimizer(model_path):\n",
    "    def custom_optimizer():\n",
    "        return CustomAdamOptimizer(learning_rate=0.001)\n",
    "\n",
    "    print(f\"Loading model from path: {model_path}\")\n",
    "\n",
    "    # Register the custom optimizer with its name before loading the model\n",
    "    with custom_object_scope({'CustomAdamOptimizer': custom_optimizer}):\n",
    "        loaded_model = keras.models.load_model(model_path)\n",
    "\n",
    "    print(f\"Loaded model from path: {model_path}\")\n",
    "    return loaded_model\n",
    "\n",
    "# Register the custom optimizer class with its name\n",
    "with custom_object_scope({'CustomAdamOptimizer': CustomAdamOptimizer}):\n",
    "    # List of pre-trained model paths\n",
    "    pretrained_model_paths = [\n",
    "        'model_0.1_0.1.keras',\n",
    "        'model_0.1_0.2.keras',\n",
    "        'model_0.1_0.3.keras',\n",
    "        'model_0.01_0.1.keras',\n",
    "        'model_0.01_0.2.keras',\n",
    "        'model_0.01_0.3.keras',\n",
    "        'model_0.001_0.1.keras',\n",
    "        'model_0.001_0.2.keras',\n",
    "        'model_0.001_0.3.keras'\n",
    "    ]\n",
    "\n",
    "# Modify the fine_tune_model function to remove the custom_optimizer_instance parameter\n",
    "def fine_tune_model(lr, epsilon, discount_factor, num_episodes, batch_size, model_path, env,\n",
    "                    early_stop_threshold=0.9, early_stop_patience=10,\n",
    "                    time_limit_minutes=30, output_file='fine_tuning_output.json'):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Load the model for fine-tuning\n",
    "    loaded_model = load_model_with_custom_optimizer(model_path)\n",
    "\n",
    "    # Clone the loaded model to start with a fresh copy for fine-tuning\n",
    "    fine_tuned_model = clone_model(loaded_model)\n",
    "    fine_tuned_model.set_weights(loaded_model.get_weights())  # Copy weights\n",
    "\n",
    "    discount_factor_fine_tune = discount_factor\n",
    "\n",
    "    episode_rewards = []\n",
    "    training_history = []\n",
    "\n",
    "    # Early stopping variables\n",
    "    best_average_reward = -float('inf')\n",
    "    early_stopping_count = 0\n",
    "\n",
    "    # Fine-tune the loaded model\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        episode_reward = 0\n",
    "\n",
    "        # Create buffers to store batch data\n",
    "        state_buffer = []\n",
    "        target_buffer = []\n",
    "\n",
    "        while True:\n",
    "            action = np.argmax(fine_tuned_model.predict(state[np.newaxis, :]))\n",
    "            next_state, reward, done = env.step(action)\n",
    "\n",
    "            episode_reward += reward\n",
    "\n",
    "            # Store data for experience replay\n",
    "            state_buffer.append(state)\n",
    "            target = reward if done else reward + discount_factor * np.max(fine_tuned_model.predict(next_state[np.newaxis, :]))\n",
    "            target_buffer.append(target)\n",
    "\n",
    "            if len(state_buffer) >= batch_size or done:\n",
    "                # Train the model using the collected batch\n",
    "                fine_tuned_model.fit(np.array(state_buffer), np.array(target_buffer), epochs=1, verbose=0)\n",
    "\n",
    "                # Clear the buffers\n",
    "                state_buffer.clear()\n",
    "                target_buffer.clear()\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "        episode_rewards.append(episode_reward)\n",
    "\n",
    "        # Log training history for this episode\n",
    "        recent_rewards = episode_rewards[-early_stop_patience:]\n",
    "        recent_average_reward = np.mean(recent_rewards)\n",
    "        training_history.append({\n",
    "            'episode': episode,\n",
    "            'average_reward': recent_average_reward\n",
    "        })\n",
    "\n",
    "        # Early stopping check\n",
    "        if recent_average_reward >= early_stop_threshold:\n",
    "            break\n",
    "\n",
    "        # Check elapsed time and stop if it exceeds the time limit\n",
    "        elapsed_time_minutes = (time.time() - start_time) / 60.0\n",
    "        if elapsed_time_minutes > time_limit_minutes:\n",
    "            print(f\"Time limit exceeded ({time_limit_minutes} minutes). Stopping fine-tuning.\")\n",
    "            break\n",
    "\n",
    "    # Save the fine-tuned model with a unique name based on hyperparameters\n",
    "    model_save_path = f\"fine_tuned_model_lr_{lr}_epsilon_{epsilon}_discount_{discount_factor}.keras\"\n",
    "    fine_tuned_model.save(model_save_path)\n",
    "\n",
    "    # Save useful output to the output file\n",
    "    output_data = {\n",
    "        'lr': lr,\n",
    "        'epsilon': epsilon,\n",
    "        'discount_factor': discount_factor_fine_tune,\n",
    "        'average_reward': recent_average_reward,  # Use recent_average_reward\n",
    "        'training_history': training_history,\n",
    "        'elapsed_time_minutes': elapsed_time_minutes\n",
    "    }\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(output_data, f, indent=4)\n",
    "\n",
    "    return output_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Define hyperparameters for fine-tuning\n",
    "    learning_rates = [0.001, 0.01, 0.1]\n",
    "    epsilons = [0.1, 0.2, 0.3]\n",
    "    discount_factors = [0.9, 0.95, 0.99]\n",
    "    num_episodes = 100  # Reduced number of episodes for faster fine-tuning\n",
    "    batch_size = 32  # Increased batch size for faster training\n",
    "    early_stop_threshold = 0.9\n",
    "    time_limit_minutes = 30  # Set the time limit for fine-tuning\n",
    "    output_file = 'fine_tuning_output.json'  # Output file name\n",
    "\n",
    "    # Use multiprocessing to fine-tune models in parallel\n",
    "    num_processes = 2  # Use all available CPU cores\n",
    "\n",
    "    # Create a list of hyperparameters to search for each model\n",
    "    hyperparameters_to_search = [(lr, epsilon, discount_factor, num_episodes, batch_size, model_path, env)\n",
    "                                 for lr in learning_rates\n",
    "                                 for epsilon in epsilons\n",
    "                                 for discount_factor in discount_factors\n",
    "                                 for model_path in pretrained_model_paths]\n",
    "\n",
    "    # Parallelize the fine-tuning process\n",
    "with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "    results = pool.starmap(\n",
    "        fine_tune_model,\n",
    "        [(lr, epsilon, discount_factor, num_episodes, batch_size, model_path, env, custom_optimizer_instance) for lr, epsilon, discount_factor in hyperparameters_to_search]\n",
    "    )\n",
    "\n",
    "\n",
    "    # Find the best hyperparameters for each model\n",
    "    best_results = []\n",
    "    for i, pretrained_model_path in enumerate(pretrained_model_paths):\n",
    "        model_results = results[i * len(hyperparameters_to_search) // len(pretrained_model_paths):\n",
    "                                (i + 1) * len(hyperparameters_to_search) // len(pretrained_model_paths)]\n",
    "        best_result = max(model_results, key=lambda x: x['average_reward'])\n",
    "        best_results.append(best_result)\n",
    "\n",
    "    # Print and save the best hyperparameters and models for each pre-trained model\n",
    "    for i, pretrained_model_path in enumerate(pretrained_model_paths):\n",
    "        best_result = best_results[i]\n",
    "        print(f\"Best Hyperparameters for {pretrained_model_path}:\")\n",
    "        print(f\"lr: {best_result['lr']}, epsilon: {best_result['epsilon']}, \"\n",
    "              f\"discount_factor: {best_result['discount_factor']}, \"\n",
    "              f\"Best Average Reward: {best_result['average_reward']}\")\n",
    "        best_fine_tuned_model = keras.models.load_model(\n",
    "            f\"fine_tuned_model_lr_{best_result['lr']}_epsilon_{best_result['epsilon']}_discount_{best_result['discount_factor']}.h5\")\n",
    "        best_fine_tuned_model.save(f'best_fine_tuned_{pretrained_model_path}.h5')\n",
    "\n",
    "    print(\"Fine-tuning is done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008b951c-2914-45f4-a448-2e0a6b89ec2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.c5.12xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.3-gpu-py37-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
